{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e514d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "# from algorithm.cMMAC import *\n",
    "# from algorithm.GPG import *\n",
    "from scheduling_util.env.platform import *\n",
    "from scheduling_util.env.env_run import *\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "def flatten(list):\n",
    "    return [y for x in list for y in x]\n",
    "\n",
    "\n",
    "def calculate_reward(master1, master2, cur_done, cur_undone):\n",
    "    weight = 1.0\n",
    "    all_task = [float(cur_done[0] + cur_undone[0]), float(cur_done[1] + cur_undone[1])]\n",
    "    fail_task = [float(cur_undone[0]), float(cur_undone[1])]\n",
    "    reward = []\n",
    "    # The ratio of requests that violate delay requirements\n",
    "    task_fail_rate = []\n",
    "    if all_task[0] != 0:\n",
    "        task_fail_rate.append(fail_task[0] / all_task[0])\n",
    "    else:\n",
    "        task_fail_rate.append(0)\n",
    "\n",
    "    if all_task[1] != 0:\n",
    "        task_fail_rate.append(fail_task[1] / all_task[1])\n",
    "    else:\n",
    "        task_fail_rate.append(0)\n",
    "\n",
    "    # The standard deviation of the CPU and memory usage\n",
    "    standard_list = []\n",
    "    use_rate1 = []\n",
    "    use_rate2 = []\n",
    "    for i in range(3):\n",
    "        use_rate1.append(master1.node_list[i].cpu / master1.node_list[i].cpu_max)\n",
    "        use_rate1.append(master1.node_list[i].mem / master1.node_list[i].mem_max)\n",
    "        use_rate2.append(master2.node_list[i].cpu / master2.node_list[i].cpu_max)\n",
    "        use_rate2.append(master2.node_list[i].mem / master2.node_list[i].mem_max)\n",
    "\n",
    "    standard_list.append(np.std(use_rate1, ddof=1))\n",
    "    standard_list.append(np.std(use_rate2, ddof=1))\n",
    "\n",
    "    reward.append(math.exp(-task_fail_rate[0]) + weight * math.exp(-standard_list[0]))\n",
    "    reward.append(math.exp(-task_fail_rate[1]) + weight * math.exp(-standard_list[1]))\n",
    "    return reward\n",
    "\n",
    "\n",
    "def to_grid_rewards(node_reward):\n",
    "    return np.array(node_reward).reshape([-1, 1])\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from scheduling_util.scheduler.KaiS import Estimator\n",
    "from scheduling_util.scheduler.generic import get_generic_act\n",
    "import scheduling_util.scheduler.UCB as ucb_scheduler\n",
    "import scheduling_util.scheduler.DQN as DQN\n",
    "from models.Informer import Informer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 初始化Informer模型\n",
    "input_size = 1  # 特征数量\n",
    "embed_size = 64  # 嵌入维度\n",
    "hidden_size = 64  # 隐藏层神经元数量\n",
    "num_layers = 2  # 编码器层数\n",
    "num_heads = 4  # 自注意力的头数\n",
    "forecast_horizon = 1  # 预测的目标步长\n",
    "\n",
    "informer_model = torch.load(\"best_informer_model.pth\", map_location=device)\n",
    "informer_model.eval()\n",
    "\n",
    "MODEL = 'KaiS'  # Options: 'KaiS', 'UCB', 'DQN-based', 'generic', 'Random', 'UCB_predict'\n",
    "kais = Estimator(7, 88, 2)\n",
    "# agent 实例化（建议全局只实例化一次）\n",
    "dqn_agent = DQN.DQNAgent(state_dim=88, action_dim=7, epsilon=0.1)  # state_dim和action_dim根据实际设置\n",
    "'''\n",
    "    s_grid = [[deploy_state, [task_num1], cpu_list1, mem_list1],[deploy_state, [task_num2], cpu_list1, mem_list1]]\n",
    "\n",
    "'''\n",
    "def get_act(model, s_grid, ava_node, **kwargs):\n",
    "    \"\"\"\n",
    "    model: string name of scheduler\n",
    "    s_grid: [[deploy_state, [task_num1], cpu_list1, mem_list1],\n",
    "             [deploy_state, [task_num2], cpu_list2, mem_list2]]\n",
    "    ava_node: available node lists\n",
    "    kwargs: context, epsilon, 可选 lookback 等\n",
    "    \"\"\"\n",
    "    if model == 'KaiS':\n",
    "        return kais.action(s_grid, ava_node, kwargs['context'], kwargs['epsilon'])\n",
    "    if model == 'UCB':\n",
    "        return ucb_scheduler.get_act(s_grid, ava_node, kwargs['context'])\n",
    "    elif model == 'DQN-based':\n",
    "        return DQN.get_act(dqn_agent, s_grid, ava_node, kwargs['context'])\n",
    "    elif model == 'generic':\n",
    "        return get_generic_act(s_grid, ava_node, kwargs['context'])\n",
    "    elif model == 'Random':\n",
    "        return [np.random.choice(ava_node[i]) for i in range(len(ava_node))]\n",
    "    elif model == 'UCB_predict':\n",
    "        # 使用 informer_model 预测未来各节点的利用率，构造替代的 cpu_list 传入 UCB\n",
    "        LOOKBACK = kwargs.get('lookback', 20)  # 回溯长度\n",
    "        try:\n",
    "            # node_resource_usage 由 execution 中维护（全局可见）\n",
    "            hist = globals().get('node_resource_usage', None)\n",
    "            # 如果没有历史或历史长度不足，则退化为直接使用当前 s_grid 的 cpu_list\n",
    "            if (hist is None) or (len(hist) == 0):\n",
    "                return ucb_scheduler.get_act(s_grid, ava_node, kwargs['context'])\n",
    "\n",
    "            # 取最近 LOOKBACK 条记录\n",
    "            seq = hist[-LOOKBACK:] if len(hist) >= LOOKBACK else hist[:]\n",
    "            seq_len = len(seq)\n",
    "            num_nodes = 6  # master1 3 + master2 3\n",
    "            # 构造输入 [batch=1, seq_len, num_nodes, 1]\n",
    "            arr = np.zeros((1, seq_len, num_nodes, 1), dtype=np.float32)\n",
    "            for t_idx, slot in enumerate(seq):\n",
    "                for i in range(3):\n",
    "                    cpu = slot['master1'][i]['cpu']\n",
    "                    cpu_max = slot['master1'][i]['cpu_max']\n",
    "                    arr[0, t_idx, i, 0] = (cpu / cpu_max) if cpu_max != 0 else 0.0\n",
    "                for i in range(3):\n",
    "                    cpu = slot['master2'][i]['cpu']\n",
    "                    cpu_max = slot['master2'][i]['cpu_max']\n",
    "                    arr[0, t_idx, 3 + i, 0] = (cpu / cpu_max) if cpu_max != 0 else 0.0\n",
    "\n",
    "            # 如果历史长度不足，用最早帧重复填充到LOOKBACK长度（Informer 训练时可能需要固定长度）\n",
    "            if seq_len < LOOKBACK:\n",
    "                pad_len = LOOKBACK - seq_len\n",
    "                pad = np.repeat(arr[:, :1, :, :], pad_len, axis=1)\n",
    "                arr = np.concatenate([pad, arr], axis=1)\n",
    "\n",
    "            x = torch.tensor(arr).to(device)  # shape [1, seq_len, num_nodes, 1]\n",
    "            with torch.no_grad():\n",
    "                # informer_model 应输出形状 [batch, horizon, num_nodes, 1]\n",
    "                pred = informer_model(x)  # tensor\n",
    "            pred = pred.cpu().numpy()\n",
    "            # 取第一个预测步\n",
    "            pred_step = pred[0, 0, :, 0]  # length num_nodes, 预测的利用率(0-1)\n",
    "\n",
    "            # 将预测利用率转换为 cpu_list 需要的格式 [pred_cpu_absolute, cpu_max]\n",
    "            cpu_list1 = s_grid[0][2]  # 当前 master1 cpu_list: [[cpu, cpu_max], ...]\n",
    "            cpu_list2 = s_grid[1][2]\n",
    "            cpu_pred_master1 = []\n",
    "            cpu_pred_master2 = []\n",
    "            for i in range(3):\n",
    "                cpu_max = float(cpu_list1[i][1])\n",
    "                pred_usage = float(np.clip(pred_step[i], 0.0, 1.0))\n",
    "                cpu_pred_master1.append([pred_usage * cpu_max, cpu_max])\n",
    "            for i in range(3):\n",
    "                cpu_max = float(cpu_list2[i][1])\n",
    "                pred_usage = float(np.clip(pred_step[3 + i], 0.0, 1.0))\n",
    "                cpu_pred_master2.append([pred_usage * cpu_max, cpu_max])\n",
    "\n",
    "            # 组装新的 s_grid，用预测的 cpu_list 替换原 cpu_list（其余信息保持不变）\n",
    "            s_grid_pred = [\n",
    "                [s_grid[0][0], s_grid[0][1], cpu_pred_master1, s_grid[0][3]],\n",
    "                [s_grid[1][0], s_grid[1][1], cpu_pred_master2, s_grid[1][3]]\n",
    "            ]\n",
    "\n",
    "            return ucb_scheduler.get_act(s_grid_pred, ava_node, kwargs['context'])\n",
    "        except Exception:\n",
    "            # 失败则退回到不使用预测的 UCB\n",
    "            return ucb_scheduler.get_act(s_grid, ava_node, kwargs['context'])\n",
    "    return [0] * int(len(s_grid[0]) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execution(RUN_TIMES, BREAK_POINT, TRAIN_TIMES, CHO_CYCLE):\n",
    "    ############ Set up according to your own needs  ###########\n",
    "    # The parameters are set to support the operation of the program, and may not be consistent with the actual system\n",
    "    vaild_node = 6  # Number of edge nodes available\n",
    "    SLOT_TIME = 0.5  # Time of one slot\n",
    "    MAX_TESK_TYPE = 12  # Number of tesk types\n",
    "    POD_CPU = 15.0  # CPU resources required for a POD\n",
    "    POD_MEM = 1.0  # Memory resources required for a POD\n",
    "    # Resource demand coefficients for different types of services\n",
    "    service_coefficient = [0.8, 0.8, 0.9, 0.9, 1.0, 1.0, 1.1, 1.1, 1.2, 1.2, 1.3, 1.3, 1.4, 1.4]\n",
    "    # Parameters related to DRL\n",
    "    epsilon = 0.5\n",
    "    gamma = 0.9\n",
    "    node_resource_usage = []\n",
    "    learning_rate = 1e-3\n",
    "    action_dim = 7\n",
    "    state_dim = 88\n",
    "    node_input_dim = 24\n",
    "    cluster_input_dim = 24\n",
    "    hid_dims = [16, 8]\n",
    "    output_dim = 8\n",
    "    max_depth = 8\n",
    "    entropy_weight_init = 1\n",
    "    exec_cap = 24\n",
    "    entropy_weight_min = 0.0001\n",
    "    entropy_weight_decay = 1e-3\n",
    "    # Parameters related to GPU\n",
    "    worker_num_gpu = 0\n",
    "    worker_gpu_fraction = 0.1\n",
    "    #####################################################################\n",
    "    ########### Init ###########\n",
    "    record = []\n",
    "    throughput_list = []\n",
    "    sum_rewards = []\n",
    "    achieve_num = []\n",
    "    achieve_num_sum = []\n",
    "    fail_num = []\n",
    "    deploy_reward = []\n",
    "    current_time = str(time.time())\n",
    "    log_dir = \"./log/{}/\".format(current_time)\n",
    "    all_rewards = []\n",
    "    order_response_rate_episode = []\n",
    "    episode_rewards = []\n",
    "    record_all_order_response_rate = []\n",
    "    # sess = tf.Session()\n",
    "    # tf.set_random_seed(1)\n",
    "    # q_estimator = Estimator(sess, action_dim, state_dim, 2, scope=\"q_estimator\", summaries_dir=log_dir)\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    # replay = ReplayMemory(memory_size=1e+6, batch_size=int(3e+3))\n",
    "    # policy_replay = policyReplayMemory(memory_size=1e+6, batch_size=int(3e+3))\n",
    "    # saver = tf.compat.v1.train.Saver()\n",
    "    global_step1 = 0\n",
    "    global_step2 = 0\n",
    "    all_task1 = get_all_task('./data/Task_1.csv')\n",
    "    all_task2 = get_all_task('./data/Task_2.csv')\n",
    "\n",
    "    # config = tf.ConfigProto(device_count={'GPU': worker_num_gpu},\n",
    "    #                         gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=worker_gpu_fraction))\n",
    "    # sess = tf.Session(config=config)\n",
    "    # orchestrate_agent = OrchestrateAgent(sess, node_input_dim, cluster_input_dim, hid_dims, output_dim, max_depth,\n",
    "    #                                      range(1, exec_cap + 1))\n",
    "    exp = {'node_inputs': [], 'cluster_inputs': [], 'reward': [], 'wall_time': [], 'node_act_vec': [],\n",
    "           'cluster_act_vec': []}\n",
    "\n",
    "    for n_iter in np.arange(RUN_TIMES):\n",
    "        ########### Initialize the setup and repeat the experiment many times ###########\n",
    "\n",
    "        batch_reward = []\n",
    "        cur_time = 0\n",
    "        entropy_weight = entropy_weight_init\n",
    "        order_response_rates = []\n",
    "\n",
    "        pre_done = [0, 0]\n",
    "        pre_undone = [0, 0]\n",
    "        context = [1, 1]\n",
    "        ############ Set up according to your own needs  ###########\n",
    "        # The parameters here are set only to support the operation of the program, and may not be consistent with the actual system\n",
    "        deploy_state = [[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1],\n",
    "                        [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0], [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
    "                        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1]]\n",
    "        deploy_state = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "\n",
    "        # Create clusters based on the hardware resources you need\n",
    "        node1_1 = Node(100.0, 4.0, [], [])  # (cpu, mem,...)\n",
    "        node1_2 = Node(200.0, 6.0, [], [])\n",
    "        node1_3 = Node(100.0, 8.0, [], [])\n",
    "        node_list1 = [node1_1, node1_2, node1_3]\n",
    "\n",
    "        node2_1 = Node(200.0, 8.0, [], [])\n",
    "        node2_2 = Node(100.0, 2.0, [], [])\n",
    "        node2_3 = Node(200.0, 6.0, [], [])\n",
    "        node_list2 = [node2_1, node2_2, node2_3]\n",
    "        # (cpu, mem,..., achieve task num, give up task num)\n",
    "        master1 = Master(200.0, 8.0, node_list1, [], all_task1, 0, 0, 0, [0] * MAX_TESK_TYPE, [0] * MAX_TESK_TYPE)\n",
    "        master2 = Master(200.0, 8.0, node_list2, [], all_task2, 0, 0, 0, [0] * MAX_TESK_TYPE, [0] * MAX_TESK_TYPE)\n",
    "        cloud = Cloud([], [], sys.maxsize, sys.maxsize)  # (..., cpu, mem)\n",
    "        ################################################################################################\n",
    "        for i in range(MAX_TESK_TYPE):\n",
    "            docker = Docker(POD_MEM * service_coefficient[i], POD_CPU * service_coefficient[i], cur_time, i, [-1])\n",
    "            cloud.service_list.append(docker)\n",
    "\n",
    "        # Crerate dockers based on deploy_state\n",
    "        for i in range(vaild_node):\n",
    "            for ii in range(MAX_TESK_TYPE):\n",
    "                dicision = deploy_state[i][ii]\n",
    "                if i < 3 and dicision == 1:\n",
    "                    j = i\n",
    "                    # if master1.node_list[j].mem >= POD_MEM * service_coefficient[ii]:\n",
    "                    docker = Docker(POD_MEM * service_coefficient[ii], POD_CPU * service_coefficient[ii], cur_time,\n",
    "                                    ii, [-1])\n",
    "                    # master1.node_list[j].mem = master1.node_list[j].mem - POD_MEM * service_coefficient[ii]\n",
    "                    master1.node_list[j].service_list.append(docker)\n",
    "\n",
    "                if i >= 3 and dicision == 1:\n",
    "                    j = i - 3\n",
    "                    # if master2.node_list[j].mem >= POD_MEM * service_coefficient[ii]:\n",
    "                    docker = Docker(POD_MEM * service_coefficient[ii], POD_CPU * service_coefficient[ii], cur_time,\n",
    "                                        ii, [-1])\n",
    "                    # master2.node_list[j].mem = master2.node_list[j].mem - POD_MEM * service_coefficient[ii]\n",
    "                    master2.node_list[j].service_list.append(docker)\n",
    "\n",
    "        ########### Each slot ###########\n",
    "        with tqdm.tqdm(total=BREAK_POINT, desc='Running simulation') as pbar:\n",
    "            # pass\n",
    "            for slot in range(BREAK_POINT):\n",
    "                cur_time = cur_time + SLOT_TIME\n",
    "                slot_usage = {\n",
    "                    'time': cur_time,\n",
    "                    'master1': [],\n",
    "                    'master2': []\n",
    "                }\n",
    "                for i in range(3):\n",
    "                    slot_usage['master1'].append({\n",
    "                        'cpu': master1.node_list[i].cpu,\n",
    "                        'cpu_max': master1.node_list[i].cpu_max,\n",
    "                        'mem': master1.node_list[i].mem,\n",
    "                        'mem_max': master1.node_list[i].mem_max\n",
    "                    })\n",
    "                    slot_usage['master2'].append({\n",
    "                        'cpu': master2.node_list[i].cpu,\n",
    "                        'cpu_max': master2.node_list[i].cpu_max,\n",
    "                        'mem': master2.node_list[i].mem,\n",
    "                        'mem_max': master2.node_list[i].mem_max\n",
    "                    })\n",
    "                node_resource_usage.append(slot_usage)\n",
    "                globals()['node_resource_usage'] = node_resource_usage  # 更新全局变量，供 UCB_predict 使用\n",
    "                ########### Each frame ###########\n",
    "                if slot % CHO_CYCLE == 0 and slot != 0:\n",
    "                    done_tasks = []\n",
    "                    undone_tasks = []\n",
    "                    curr_tasks_in_queue = []\n",
    "                    # Get task state, include successful, failed, and unresolved\n",
    "                    for i in range(MAX_TESK_TYPE):\n",
    "                        done_tasks.append(float(master1.done_kind[i] + master2.done_kind[i]))\n",
    "                        undone_tasks.append(float(master1.undone_kind[i] + master2.undone_kind[i]))\n",
    "                    for i in range(3):\n",
    "                        tmp = [0.0] * MAX_TESK_TYPE\n",
    "                        for j in range(len(master1.node_list[i].task_queue)):\n",
    "                            tmp[master1.node_list[i].task_queue[j][0]] = tmp[master1.node_list[i].task_queue[j][0]] + 1.0\n",
    "                        curr_tasks_in_queue.append(tmp)\n",
    "                    for i in range(3):\n",
    "                        tmp = [0.0] * MAX_TESK_TYPE\n",
    "                        for k in range(len(master2.node_list[i].task_queue)):\n",
    "                            tmp[master2.node_list[i].task_queue[k][0]] = tmp[master2.node_list[i].task_queue[k][0]] + 1\n",
    "                        curr_tasks_in_queue.append(tmp)\n",
    "                    if slot != CHO_CYCLE:\n",
    "                        exp['reward'].append(float(sum(deploy_reward)) / float(len(deploy_reward)))\n",
    "                        deploy_reward = []\n",
    "                        exp['wall_time'].append(cur_time)\n",
    "\n",
    "                    deploy_state_float = []\n",
    "                    for i in range(len(deploy_state)):\n",
    "                        tmp = []\n",
    "                        for j in range(len(deploy_state[0])):\n",
    "                            tmp.append(float(deploy_state[i][j]))\n",
    "                        deploy_state_float.append(tmp)\n",
    "                        # Make decision of orchestration\n",
    "\n",
    "\n",
    "\n",
    "                # Get current task\n",
    "                master1 = update_task_queue(master1, cur_time, 0)\n",
    "                master2 = update_task_queue(master2, cur_time, 1)\n",
    "                task1 = [-1]\n",
    "                task2 = [-1]\n",
    "                if len(master1.task_queue) != 0:\n",
    "                    task1 = master1.task_queue[0]\n",
    "                    del master1.task_queue[0]\n",
    "                if len(master2.task_queue) != 0:\n",
    "                    task2 = master2.task_queue[0]\n",
    "                    del master2.task_queue[0]\n",
    "                curr_task = [task1, task2]\n",
    "                ava_node = []\n",
    "\n",
    "                for i in range(len(curr_task)):\n",
    "                    tmp_list = [6]  # Cloud computing\n",
    "                    for ii in range(len(deploy_state)):\n",
    "                        if deploy_state[ii][curr_task[i][0]] == 1:\n",
    "                            tmp_list.append(ii)\n",
    "                    ava_node.append(tmp_list)\n",
    "\n",
    "                # Current state of CPU and memory\n",
    "                cpu_list1 = []\n",
    "                mem_list1 = []\n",
    "                cpu_list2 = []\n",
    "                mem_list2 = []\n",
    "                task_num1 = [len(master1.task_queue)]\n",
    "                task_num2 = [len(master2.task_queue)]\n",
    "                for i in range(3):\n",
    "                    cpu_list1.append([master1.node_list[i].cpu, master1.node_list[i].cpu_max])\n",
    "                    mem_list1.append([master1.node_list[i].mem, master1.node_list[i].mem_max])\n",
    "                    task_num1.append(len(master1.node_list[i].task_queue))\n",
    "                for i in range(3):\n",
    "                    cpu_list2.append([master2.node_list[i].cpu, master2.node_list[i].cpu_max])\n",
    "                    mem_list2.append([master2.node_list[i].mem, master2.node_list[i].mem_max])\n",
    "                    task_num2.append(len(master2.node_list[i].task_queue))\n",
    "                s_grid = [[deploy_state, [task_num1], cpu_list1, mem_list1],[deploy_state, [task_num2], cpu_list1, mem_list1]]\n",
    "                # Dispatch decision\n",
    "                if MODEL == 'KaiS':\n",
    "                    act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = get_act('KaiS',  s_grid, ava_node, context=context, epsilon=epsilon)\n",
    "                if MODEL == 'generic':\n",
    "                    act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = get_act('generic', s_grid, ava_node, context=context)\n",
    "                if MODEL == 'UCB':\n",
    "                    act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = get_act('UCB', s_grid, ava_node, context=context)\n",
    "                if MODEL == 'DQN-based':\n",
    "                    act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = get_act('DQN-based', s_grid, ava_node, context=context)\n",
    "                if MODEL == 'Random':\n",
    "                    act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = get_act('Random', s_grid, ava_node, context=context)\n",
    "                if MODEL == 'UCB_predict':\n",
    "                    act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = get_act('UCB_predict', s_grid, ava_node, context=context)\n",
    "                # act, valid_action_prob_mat, policy_state, action_choosen_mat, \\\n",
    "                # curr_state_value, curr_neighbor_mask, next_state_ids = q_estimator.action(s_grid, ava_node, context,\n",
    "                                                                                        #   epsilon)\n",
    "                # Put the current task on the queue based on dispatch decision\n",
    "                for i in range(len(act)):\n",
    "                    if curr_task[i][0] == -1:\n",
    "                        continue\n",
    "                    if act[i] == 6:\n",
    "                        cloud.task_queue.append(curr_task[i])\n",
    "                        continue\n",
    "                    if act[i] >= 0 and act[i] < 3:\n",
    "                        master1.node_list[act[i]].task_queue.append(curr_task[i])\n",
    "                        continue\n",
    "                    if act[i] >= 3 and act[i] < 6:\n",
    "                        master2.node_list[act[i] - 3].task_queue.append(curr_task[i])\n",
    "                        continue\n",
    "                    else:\n",
    "                        pass\n",
    "                # Update state of task\n",
    "                for i in range(3):\n",
    "                    master1.node_list[i].task_queue, undone, undone_kind = check_queue(master1.node_list[i].task_queue,\n",
    "                                                                                    cur_time)\n",
    "                    for j in undone_kind:\n",
    "                        master1.undone_kind[j] = master1.undone_kind[j] + 1\n",
    "                    master1.undone = master1.undone + undone[0]\n",
    "                    master2.undone = master2.undone + undone[1]\n",
    "\n",
    "                    master2.node_list[i].task_queue, undone, undone_kind = check_queue(master2.node_list[i].task_queue,\n",
    "                                                                                    cur_time)\n",
    "                    for j in undone_kind:\n",
    "                        master2.undone_kind[j] = master2.undone_kind[j] + 1\n",
    "                    master1.undone = master1.undone + undone[0]\n",
    "                    master2.undone = master2.undone + undone[1]\n",
    "\n",
    "                cloud.task_queue, undone, undone_kind = check_queue(cloud.task_queue, cur_time)\n",
    "                master1.undone = master1.undone + undone[0]\n",
    "                master2.undone = master2.undone + undone[1]\n",
    "\n",
    "                # Update state of dockers in every node\n",
    "                for i in range(3):\n",
    "                    master1.node_list[i], undone, done, done_kind, undone_kind = update_docker(master1.node_list[i],\n",
    "                                                                                            cur_time,\n",
    "                                                                                            service_coefficient, POD_CPU, POD_MEM)\n",
    "                    for j in range(len(done_kind)):\n",
    "                        master1.done_kind[done_kind[j]] = master1.done_kind[done_kind[j]] + 1\n",
    "                    for j in range(len(undone_kind)):\n",
    "                        master1.undone_kind[undone_kind[j]] = master1.undone_kind[undone_kind[j]] + 1\n",
    "                    master1.undone = master1.undone + undone[0]\n",
    "                    master2.undone = master2.undone + undone[1]\n",
    "                    master1.done = master1.done + done[0]\n",
    "                    master2.done = master2.done + done[1]\n",
    "\n",
    "                    master2.node_list[i], undone, done, done_kind, undone_kind = update_docker(master2.node_list[i],\n",
    "                                                                                            cur_time,\n",
    "                                                                                            service_coefficient, POD_CPU, POD_MEM)\n",
    "                    for j in range(len(done_kind)):\n",
    "                        master1.done_kind[done_kind[j]] = master1.done_kind[done_kind[j]] + 1\n",
    "                    for j in range(len(undone_kind)):\n",
    "                        master1.undone_kind[undone_kind[j]] = master1.undone_kind[undone_kind[j]] + 1\n",
    "                    master1.undone = master1.undone + undone[0]\n",
    "                    master2.undone = master2.undone + undone[1]\n",
    "                    master1.done = master1.done + done[0]\n",
    "                    master2.done = master2.done + done[1]\n",
    "\n",
    "                cloud, undone, done, done_kind, undone_kind = update_docker(cloud, cur_time, service_coefficient, POD_CPU, POD_MEM)\n",
    "                master1.undone = master1.undone + undone[0]\n",
    "                master2.undone = master2.undone + undone[1]\n",
    "                master1.done = master1.done + done[0]\n",
    "                master2.done = master2.done + done[1]\n",
    "\n",
    "                cur_done = [master1.done - pre_done[0], master2.done - pre_done[1]]\n",
    "                cur_undone = [master1.undone - pre_undone[0], master2.undone - pre_undone[1]]\n",
    "\n",
    "                pre_done = [master1.done, master2.done]\n",
    "                pre_undone = [master1.undone, master2.undone]\n",
    "\n",
    "                achieve_num.append(sum(cur_done))\n",
    "                fail_num.append(sum(cur_undone))\n",
    "                immediate_reward = calculate_reward(master1, master2, cur_done, cur_undone)\n",
    "\n",
    "                record.append([master1, master2, cur_done, cur_undone, immediate_reward])\n",
    "\n",
    "                deploy_reward.append(sum(immediate_reward))\n",
    "\n",
    "                if slot != 0 and MODEL == 'KaiS':\n",
    "                    r_grid = to_grid_rewards(immediate_reward)\n",
    "                    target_batch = kais.compute_targets(action_mat_prev, s_grid, r_grid, gamma)\n",
    "                    # targets_batch = q_estimator.compute_targets(action_mat_prev, s_grid, r_grid, gamma)\n",
    "\n",
    "                    # Advantage for policy network.\n",
    "                    advantage = kais.compute_advantage(curr_state_value_prev, next_state_ids_prev,\n",
    "                                                    s_grid, r_grid, gamma)\n",
    "                    # advantage = q_estimator.compute_advantage(curr_state_value_prev, next_state_ids_prev,\n",
    "                    #                                           s_grid, r_grid, gamma)\n",
    "                    # if curr_task[0][0] != -1 and curr_task[1][0] != -1:\n",
    "                    #     replay.add(state_mat_prev, action_mat_prev, targets_batch, s_grid)\n",
    "                    #     policy_replay.add(policy_state_prev, action_choosen_mat_prev, advantage, curr_neighbor_mask_prev)\n",
    "                if MODEL == 'KaiS':\n",
    "                    # For updating\n",
    "                    state_mat_prev = s_grid\n",
    "                    action_mat_prev = valid_action_prob_mat\n",
    "                    action_choosen_mat_prev = action_choosen_mat\n",
    "                    curr_neighbor_mask_prev = curr_neighbor_mask\n",
    "                    policy_state_prev = policy_state\n",
    "\n",
    "                # # for computing advantage\n",
    "                    curr_state_value_prev = curr_state_value\n",
    "                    next_state_ids_prev = next_state_ids\n",
    "                # global_step1 += 1\n",
    "                # global_step2 += 1\n",
    "\n",
    "                all_rewards.append(sum(immediate_reward))\n",
    "                batch_reward.append(immediate_reward)\n",
    "\n",
    "                if (sum(cur_done) + sum(cur_undone)) != 0:\n",
    "                    order_response_rates.append(float(sum(cur_done) / (sum(cur_done) + sum(cur_undone))))\n",
    "                else:\n",
    "                    order_response_rates.append(0)\n",
    "                # print('slot =', slot, ', cur_time =', cur_time, ', immediate_reward =', immediate_reward,\n",
    "                    # ', order_response_rate =', order_response_rates[-1], ', current_achieve_number =',\n",
    "                    # sum(cur_done), ', current_fail_number =', sum(cur_undone))\n",
    "                pbar.update(1)\n",
    "        sum_rewards.append(float(sum(all_rewards)) / float(len(all_rewards)))\n",
    "        all_rewards = []\n",
    "\n",
    "        all_number = sum(achieve_num) + sum(fail_num)\n",
    "        throughput_list.append(sum(achieve_num) / float(all_number))\n",
    "        print('throughput_list_all =', throughput_list[-1], '\\ncurrent_achieve_number =', sum(achieve_num),\n",
    "              ', current_fail_number =', sum(fail_num))\n",
    "        achieve_num = []\n",
    "        fail_num = []\n",
    "\n",
    "        episode_reward = np.sum(batch_reward[1:])\n",
    "        episode_rewards.append(episode_reward)\n",
    "        n_iter_order_response_rate = np.mean(order_response_rates[1:])\n",
    "        order_response_rate_episode.append(n_iter_order_response_rate)\n",
    "        record_all_order_response_rate.append(order_response_rates)\n",
    "        # update value network\n",
    "        # for _ in np.arange(TRAIN_TIMES):\n",
    "        #     # batch_s, _, batch_r, _ = replay.sample()\n",
    "        #     # q_estimator.update_value(batch_s, batch_r, 1e-3, global_step1)\n",
    "        #     global_step1 += 1\n",
    "\n",
    "        # # update policy network\n",
    "        # for _ in np.arange(TRAIN_TIMES):\n",
    "        #     # batch_s, batch_a, batch_r, batch_mask = policy_replay.sample()\n",
    "        #     # q_estimator.update_policy(batch_s, batch_r.reshape([-1, 1]), batch_a, batch_mask, learning_rate,\n",
    "        #                             #   global_step2)\n",
    "        #     global_step2 += 1\n",
    "    #     saver.save(sess, \"./model/model.ckpt\")\n",
    "    # saver.save(sess, \"./model/model_before_testing.ckpt\")\n",
    "    # tf.reset_default_graph()\n",
    "    time_str = str(time.time())\n",
    "    # with open(\"./result/\" + time_str + \".json\", \"w\") as f:\n",
    "    #     json.dump(record, f)\n",
    "    with open(\"./result/node_resource_usage_\" + MODEL + \".json\", \"w\") as f:\n",
    "        json.dump(node_resource_usage, f)\n",
    "    return throughput_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd46d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running simulation:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 6 at dim 2 (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m CHO_CYCLE = \u001b[32m1000\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m##############################################################\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mexecution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRUN_TIMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTASK_NUM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_TIMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHO_CYCLE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 221\u001b[39m, in \u001b[36mexecution\u001b[39m\u001b[34m(RUN_TIMES, BREAK_POINT, TRAIN_TIMES, CHO_CYCLE)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# Dispatch decision\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m MODEL == \u001b[33m'\u001b[39m\u001b[33mKaiS\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = \u001b[43mget_act\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mKaiS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43ms_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mava_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m MODEL == \u001b[33m'\u001b[39m\u001b[33mgeneric\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    223\u001b[39m     act, valid_action_prob_mat, policy_state, action_choosen_mat, curr_state_value, curr_neighbor_mask, next_state_ids = get_act(\u001b[33m'\u001b[39m\u001b[33mgeneric\u001b[39m\u001b[33m'\u001b[39m, s_grid, ava_node, context=context)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mget_act\u001b[39m\u001b[34m(model, s_grid, ava_node, **kwargs)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_act\u001b[39m(model, s_grid, ava_node,**kwargs):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model == \u001b[33m'\u001b[39m\u001b[33mKaiS\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m         \u001b[38;5;66;03m# act, valid_action_prob_mat, policy_state, action_choosen_mat, \\\u001b[39;00m\n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m#     curr_state_value, curr_neighbor_mask, next_state_ids = q_estimator.action(s_grid, ava_node, kwargs['context'], kwargs['epsilon'])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkais\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mava_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepsilon\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model == \u001b[33m'\u001b[39m\u001b[33mUCB\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# Placeholder for UCB logic\u001b[39;00m\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m ucb_scheduler.get_act(s_grid, ava_node, kwargs[\u001b[33m'\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Graduate_25_P2P/scheduling_util/scheduler/KaiS.py:262\u001b[39m, in \u001b[36mEstimator.action\u001b[39m\u001b[34m(self, s, ava_node, context, epsilon)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maction\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, ava_node, context, epsilon):\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# change s to tensor\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     s = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    264\u001b[39m         s = s.unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: expected sequence of length 6 at dim 2 (got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "############ Set up according to your own needs  ###########\n",
    "# The parameters are set to support the operation of the program, and may not be consistent with the actual system\n",
    "RUN_TIMES = 1\n",
    "TASK_NUM = 1000\n",
    "TRAIN_TIMES = 50\n",
    "CHO_CYCLE = 1000\n",
    "##############################################################\n",
    "execution(RUN_TIMES, TASK_NUM, TRAIN_TIMES, CHO_CYCLE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workload_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
